---
# **第一部分：分类模型评估指标学习指南**

## **1. 准确率 (Accuracy)**

*   **层次一：掌握定义与公式 (The "What")**
    *   **定义：** 预测正确的样本数占总样本数的比例。
    *   **公式：** `Accuracy = (TP + TN) / (TP + TN + FP + FN)`

*   **层次二：建立直观解读与业务动机 (The "Why")**
    *   **直观解读：** 这是最朴素的“好坏”标准，回答了“模型答对了多少题？”这个问题。如果一个模型有95%的准确率，意味着它在100次预测中，平均有95次是正确的。
    *   **业务动机：** 在各类别的业务重要性相近，且样本数量也比较均衡的场景下，准确率是一个非常好的、易于向非技术人员解释的宏观指标。例如，在一个识别猫和狗的图片分类任务中，如果猫和狗的图片数量差不多，那么准确率就能很好地衡量模型整体的识别能力。

*   **层次三：分析适用场景与优缺点 (The "When")**
    *   **优点：** 简单直观，易于计算和沟通。
    *   **缺点与陷阱：** 在样本不均衡时，它会给出极具误导性的结论。 正如文本所说，在99%都是负样本的情况下，一个“无脑”预测所有样本为负的模型，其准确率高达99%，但它对识别正样本毫无用处。

*   **层次四：理解权衡与可视化 (The "Trade-offs")**
    *   **权衡关系：** 准确率的权衡主要体现在它自身对“类别不平衡”的敏感性上。它将一个“真负例 (TN)”的正确预测和一个“真正例 (TP)”的正确预测看得同等重要。这种“一视同仁”的特性，在不均衡场景下就成了缺点。它牺牲了对少数类别的洞察力，来换取一个宏观的、看似不错的数字。

*   **层次五：动手实践与对比学习 (The "How to Apply")**
    *   **动手实践：** 构造一个包含99个负样本和1个正样本的列表。现在，你的“模型”预测这100个样本全为负。亲手计算一下混淆矩阵（TP=0, FN=1, FP=0, TN=99），然后计算准确率。你会得到99%的惊人结果，从而深刻理解其陷阱。
    *   **对比学习：** 在上述场景中，对比计算F1分数（结果为0），你会立刻明白为什么在类别不平衡时，我们必须使用F1分数或AUC这类更鲁棒的指标。

---

## **2. 精确率 (Precision) 与 3. 召回率 (Recall)**

（这对指标通常需要放在一起理解，尤其是在权衡层面）

*   **层次一：掌握定义与公式 (The "What")**
    *   **精确率 (Precision) 定义：** 所有被模型预测为正例的样本中，实际为正例的比例（查准率）。 公式：`Precision = TP / (TP + FP)`。
    *   **召回率 (Recall) 定义：** 实际为正例的样本中，被模型成功预测为正例的比例（查全率）。 公式：`Recall = TP / (TP + FN)`。

*   **层次二：建立直观解读与业务动机 (The "Why")**
    *   **直观解读：**
        *   **精确率：** 回答的是“模型说它是正例的那些样本里，有多少是真的？”。它代表了模型的“审慎”程度。
        *   **召回率：** 回答的是“所有真正的正例，模型找回来了多少？”。它代表了模型的“宽容”或“全面”程度。
    *   **业务动机：**
        *   **高精确率场景（宁缺毋滥）：** 如文本所言，垃圾邮件检测。我们最关心的是“别把好邮件错杀”，即FP要尽可能低，所以精确率是关键。
        *   **高召回率场景（宁可错杀三千，不可放过一个）：** 如文本所言，癌症诊断。我们最关心的是“别漏掉任何一个病人”，即FN要尽可能低，所以召回率是关键。

*   **层次三：分析适用场景与优缺点 (The "When")**
    *   **优点：** 它们能有效地评估模型在不均衡数据集上对少数类的表现。
    *   **缺点：** 单独看其中任何一个都没有意义。一个只预测一个样本为正（且猜对了）的模型，精确率100%但召回率极低。一个把所有样本都预测为正的模型，召回率100%但精确率极低。

*   **层次四：理解权衡与可视化 (The "Trade-offs")**
    *   **权衡关系：** 精确率和召回率是天生的“对手”。要提高精确率，模型需要变得更“挑剔”，只在非常有把握时才预测为正，这必然会导致一些模棱两可的正样本被放弃（FN增加），从而降低召回率。反之亦然。
    *   **可视化：** P-R曲线（Precision-Recall Curve）是专门用来可视化这种权衡的工具。曲线的横轴是召回率，纵轴是精确率。一个优秀的模型，其P-R曲线会尽可能地靠近右上角。

*   **层次五：动手实践与对比学习 (The "How to Apply")**
    *   **动手实践：** 想象一个分类器输出的是0到1的概率。当你把分类阈值从0.5调高到0.8时，思考一下TP, FP, FN会如何变化，进而推导出精确率和召回率会如何变化。（答案：阈值提高，模型更“挑剔”，FP会减少，TP也可能减少，FN可能增加。因此精确率倾向于升高，召回率倾向于降低）。

---

## **4. F1 分数 (F1-Score)**

*   **层次一：掌握定义与公式 (The "What")**
    *   **定义：** 精确率和召回率的调和平均数。
    *   **公式：** `F1 = 2 * (Precision * Recall) / (Precision + Recall)`

*   **层次二：建立直观解读与业务动机 (The "Why")**
    *   **直观解读：** F1分数是寻找精确率和召回率之间“最佳平衡点”的一种方式。它不是简单的算术平均，而是调和平均，这意味着它对较低的那个值更敏感。只有当精确率和召回率二者都较高时，F1分数才会高。
    *   **业务动机：** 当你无法明确在精确率和召回率之间做取舍，或者希望二者都表现良好时，F1分数提供了一个单一、便捷的综合评估指标。

*   **层次三：分析适用场景与优缺点 (The "When")**
    *   **优点：** 在类别不平衡的情况下是比准确率好得多的评估指标。
    *   **缺点：** 它假设精确率和召回率同等重要。但在某些业务场景下，我们可能更看重其中一个（例如癌症诊断更看重召回率）。（注：在这种情况下可以使用F-beta分数，它是F1的一般化形式）。

*   **层次四：理解权衡与可视化 (The "Trade-offs")**
    *   **权衡关系：** F1分数本身就是对精确率-召回率这对矛盾体进行权衡和调和的结果。它的目标是在P-R曲线上找到一个综合最优的点。

*   **层次五：动手实践与对比学习 (The "How to Apply")**
    *   **动手实践：** 尝试计算两种情况下的F1分数：（1）P=0.9, R=0.9；（2）P=1.0, R=0.1）。

---
# **第二部分：回归模型评估指标学习指南**

## **1. 平均绝对误差 (MAE)**

*   **层次一：掌握定义与公式 (The "What")**
    *   **定义：** 预测值与真实值之差的绝对值的平均数。
*   **层次二：建立直观解读与业务动机 (The "Why")**
    *   ...

## **2. 均方误差 (MSE) & 3. 均方根误差 (RMSE)**
*   ...

## **4. 决定系数 (R-Squared, R²)**
*   ...

## **5. 可释方差 (Explained Variance)**
*   ...

---
# **第三部分：聚类模型评估指标学习指南**

## **1. 轮廓系数 (Silhouette Coefficient)**
*   ...

## **2. Calinski-Harabasz 指数 (CH 指数)**
*   ...

---
# **第四部分：关联规则指标学习指南**

## **1. 支持度 (Support)**
*   ...

## **2. 置信度 (Confidence)**
*   ...

## **3. 提升度 (Lift)**
*   ...

---
# **第五部分：强化学习指标学习指南**

## **1. 平均奖励 (avg-reward)**
*   ...

